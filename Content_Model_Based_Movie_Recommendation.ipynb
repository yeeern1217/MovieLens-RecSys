{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "JbdngmepFgVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as pp\n",
        "from torch_geometric.data import HeteroData, download_url, extract_zip\n",
        "from keras.layers import Dropout, Flatten, Activation, Input, Embedding, BatchNormalization, Dense, dot\n",
        "from keras.optimizers import Adam\n",
        "from pylab import rcParams\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.sparse as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "6MLX4hX8f8bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download(url, root=os.getcwd()) -> None:\n",
        "    # ref: https://pytorch-geometric.readthedocs.io/en/stable/_modules/torch_geometric/datasets/movie_lens_100k.html#MovieLens100K\n",
        "    path = download_url(url, root)\n",
        "    extract_zip(path, root)\n",
        "    os.remove(path)\n",
        "\n",
        "    folder_name = url.split(\"/\")[-1].split(\".\")[0]\n",
        "    # folder = os.path.join(root, folder_name)\n",
        "    # fs.rm(raw_dir)\n",
        "    # os.rename(folder, raw_dir)\n",
        "    return os.path.join(root, folder_name)\n",
        "\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "\n",
        "raw_file_names = [\n",
        "    \"u.item\",\n",
        "    \"u.user\",\n",
        "    \"u.data\",\n",
        "]\n",
        "# ['u.item', 'u.user', 'u1.base', 'u1.test']"
      ],
      "metadata": {
        "id": "CAdr4osSFLnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_HEADERS = [\"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\"]\n",
        "MOVIE_HEADERS = [\n",
        "    \"item_id\",\n",
        "    \"title\",\n",
        "    \"release_date\",\n",
        "    \"video_release_date\",\n",
        "    \"IMDb URL\",\n",
        "    \"unknown\",\n",
        "    \"Action\",\n",
        "    \"Adventure\",\n",
        "    \"Animation\",\n",
        "    \"Children's\",\n",
        "    \"Comedy\",\n",
        "    \"Crime\",\n",
        "    \"Documentary\",\n",
        "    \"Drama\",\n",
        "    \"Fantasy\",\n",
        "    \"Film-Noir\",\n",
        "    \"Horror\",\n",
        "    \"Musical\",\n",
        "    \"Mystery\",\n",
        "    \"Romance\",\n",
        "    \"Sci-Fi\",\n",
        "    \"Thriller\",\n",
        "    \"War\",\n",
        "    \"Western\",\n",
        "]\n",
        "RATING_HEADERS = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
        "\n",
        "\n",
        "folder_path = download(url)\n",
        "raw_paths = [os.path.join(folder_path, i) for i in raw_file_names]"
      ],
      "metadata": {
        "id": "VY6qyyMeE7WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CjsFd_laV5P"
      },
      "outputs": [],
      "source": [
        "user_df = pd.read_csv(\n",
        "    raw_paths[1],\n",
        "    sep=\"|\",\n",
        "    header=None,\n",
        "    names=USER_HEADERS,\n",
        "    # index_col='user_id',\n",
        "    encoding=\"ISO-8859-1\",\n",
        ")\n",
        "\n",
        "item_df = pd.read_csv(\n",
        "    raw_paths[0],\n",
        "    sep=\"|\",\n",
        "    header=None,\n",
        "    names=MOVIE_HEADERS,\n",
        "    # index_col='item_id',\n",
        "    encoding=\"ISO-8859-1\",\n",
        ")\n",
        "\n",
        "rating_df = pd.read_csv(\n",
        "    raw_paths[2],\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=RATING_HEADERS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_df"
      ],
      "metadata": {
        "id": "nHmKcLvwYwS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_df"
      ],
      "metadata": {
        "id": "qC3DdQj6Y0Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_df"
      ],
      "metadata": {
        "id": "-bfyGC8XY1ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "n2pYOQQaVJK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "FiJVSZjNdvsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- User Profile Creation ---\n",
        "\n",
        "# Consider ratings of 4 or higher as a positive interaction.\n",
        "positive_ratings = rating_df[rating_df['rating'] >= 4]\n",
        "\n",
        "# Get the genre columns from the item_df\n",
        "genre_cols = item_df.columns[item_df.columns.str.startswith(('Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'))]\n",
        "\n",
        "# Merge positive ratings with movie genres\n",
        "merged_df = pd.merge(positive_ratings, item_df, left_on='item_id', right_on='item_id')\n",
        "\n",
        "# Create user profiles by averaging the genres of movies they liked\n",
        "user_profiles = merged_df.groupby('user_id')[genre_cols].mean()\n",
        "\n",
        "print(\"✅ User profiles created. Sample:\")\n",
        "print(user_profiles.head())"
      ],
      "metadata": {
        "id": "nt9T9AsB5CKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Negative Sampling and Dataset Creation ---\n",
        "\n",
        "def create_training_set(ratings, all_item_ids, neg_sample_ratio=3):\n",
        "    \"\"\"\n",
        "    Creates a training dataset with positive and negative samples.\n",
        "    \"\"\"\n",
        "    # Get the set of movies each user has already rated for quick lookups\n",
        "    rated_movies_by_user = ratings.groupby('user_id')['item_id'].apply(set)\n",
        "\n",
        "    positive_samples = ratings[ratings['rating'] >= 4]\n",
        "\n",
        "    training_data = []\n",
        "\n",
        "    print(\"Generating training data with negative sampling...\")\n",
        "    # Create positive and negative samples\n",
        "    for _, row in tqdm(positive_samples.iterrows(), total=positive_samples.shape[0]):\n",
        "        user_id = int(row['user_id'])\n",
        "        item_id = int(row['item_id'])\n",
        "\n",
        "        # 1. Add the positive sample\n",
        "        training_data.append({'user_id': user_id, 'item_id': item_id, 'target': 1})\n",
        "\n",
        "        # 2. Add negative samples\n",
        "        for _ in range(neg_sample_ratio):\n",
        "            while True:\n",
        "                # Randomly pick a movie ID\n",
        "                random_item_id = random.choice(all_item_ids)\n",
        "                # Check if it's a true negative (user hasn't rated it)\n",
        "                if random_item_id not in rated_movies_by_user.get(user_id, set()):\n",
        "                    training_data.append({'user_id': user_id, 'item_id': random_item_id, 'target': 0})\n",
        "                    break\n",
        "\n",
        "    return pd.DataFrame(training_data)\n",
        "\n",
        "all_item_ids = item_df['item_id'].unique()\n",
        "training_df = create_training_set(rating_df, all_item_ids)\n",
        "\n",
        "print(f\"\\n✅ Training set created with {len(training_df)} samples.\")\n",
        "print(\"Sample of the training set:\")\n",
        "print(training_df.head())"
      ],
      "metadata": {
        "id": "gKIiYK005nIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Corrected Step 3: Combine Features into a Single DataFrame ---\n",
        "\n",
        "# The user profile creation is correct, but let's ensure the column name is 'item_id'\n",
        "user_profiles = merged_df.groupby('user_id')[genre_cols].mean()\n",
        "\n",
        "\n",
        "# The training_df creation is correct, but ensure the column names are consistent\n",
        "all_item_ids = item_df.index.unique() # Get IDs from the index now\n",
        "training_df = create_training_set(rating_df, all_item_ids) # This function is still correct\n",
        "training_df.rename(columns={'item_id': 'item_id'}, inplace=True) # Rename for consistency\n",
        "\n",
        "# --- Merge all features into the training DataFrame ---\n",
        "\n",
        "# Merge user profiles (user's taste)\n",
        "training_df = pd.merge(training_df, user_profiles, on='user_id', how='left')\n",
        "# Rename user profile genres to distinguish them from movie genres\n",
        "training_df.rename(columns={g: f'user_{g}' for g in genre_cols}, inplace=True)\n",
        "\n",
        "\n",
        "# Merge item (movie) features using the index of item_df\n",
        "# This is the corrected line:\n",
        "training_df = pd.merge(training_df, item_df[genre_cols], left_on='item_id', right_index=True, how='left')\n",
        "\n",
        "# Fill any potential NaNs (for users who might not have a profile yet)\n",
        "training_df.fillna(0, inplace=True)\n",
        "\n",
        "print(\"\\n✅ Corrected - Final training DataFrame with all features:\")\n",
        "print(training_df.head())"
      ],
      "metadata": {
        "id": "qBG_kKDMRSBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling"
      ],
      "metadata": {
        "id": "29_e5BpZVNn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- XGBoost Model Training ---\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "features = [col for col in training_df.columns if col not in ['user_id', 'item_id', 'target']]\n",
        "X = training_df[features]\n",
        "y = training_df['target']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "# Initialize and train the XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False # Suppress a warning\n",
        ")\n",
        "\n",
        "print(\"\\nTraining XGBoost model...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluation ---\n",
        "print(\"\\nEvaluating model...\")\n",
        "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"✅ Model training complete. ROC AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "DBxOJla2RlWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_id, model, user_profiles, item_df, rating_df, top_n=10):\n",
        "    \"\"\"\n",
        "    Generates top N movie recommendations for a given user.\n",
        "    \"\"\"\n",
        "    # Get movies the user has already rated\n",
        "    rated_item_ids = rating_df[rating_df['user_id'] == user_id]['item_id'].unique()\n",
        "\n",
        "    # Create a DataFrame of candidate movies (all movies not yet rated)\n",
        "    candidate_movies = item_df[~item_df['item_id'].isin(rated_item_ids)].copy()\n",
        "    candidate_movies['user_id'] = user_id\n",
        "\n",
        "    # --- FIX STARTS HERE ---\n",
        "\n",
        "    # 1. Create a copy of user profiles to avoid modifying the original DataFrame.\n",
        "    user_profile_to_merge = user_profiles.copy()\n",
        "\n",
        "    # 2. Rename the columns to match the feature names used in training (e.g., 'Action' -> 'user_Action').\n",
        "    user_profile_to_merge.columns = [f'user_{col}' for col in user_profile_to_merge.columns]\n",
        "\n",
        "    # 3. Merge the prepared user profile data. Since user_profiles is indexed by user_id,\n",
        "    #    we merge on the index. This avoids column name collisions.\n",
        "    candidate_movies = pd.merge(candidate_movies, user_profile_to_merge, left_on='user_id', right_index=True, how='left')\n",
        "\n",
        "    # 4. Fill any NaNs that might result from the merge (e.g., a user with no positive ratings).\n",
        "    candidate_movies.fillna(0, inplace=True)\n",
        "\n",
        "    # `features` is the list of column names the model was trained on.\n",
        "    # It is captured from the global scope when this function is called.\n",
        "    # Now candidate_movies has all the necessary columns with the correct names.\n",
        "    candidate_features = candidate_movies[features]\n",
        "\n",
        "    # --- FIX ENDS HERE ---\n",
        "\n",
        "    # Predict the probability of liking each candidate movie\n",
        "    candidate_movies['recommendation_score'] = model.predict_proba(candidate_features)[:, 1]\n",
        "\n",
        "    # Sort by score and return the top N\n",
        "    recommendations = candidate_movies.sort_values('recommendation_score', ascending=False).head(top_n)\n",
        "\n",
        "    return recommendations[['item_id', 'title', 'recommendation_score']]\n",
        "\n",
        "# --- Get recommendations for a sample user ---\n",
        "# This part of your code remains the same.\n",
        "sample_user_id = 50\n",
        "print(f\"\\n🚀 Top 10 Recommendations for User ID {sample_user_id}:\")\n",
        "recommendations = get_recommendations(sample_user_id, xgb_model, user_profiles, item_df, rating_df)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "id": "vlIdQcLRRnAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}